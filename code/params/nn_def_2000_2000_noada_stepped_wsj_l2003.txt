layers {
  name: "Layer1"
  input_dim: -1
  num_units: 2000
  type: SIGMOID
  init_params {
    wt_sigma: 3.0
    biases_min: -5
    biases_max: -3
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.1
    epsilon_anneal_rate: 0.99
    momentum: 0.5
    start_epoch: 0
    end_epoch: 2
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.1
    epsilon_anneal_rate: 0.99
    momentum: 0.9
    start_epoch: 3
    end_epoch: 8
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.025
    epsilon_anneal_rate: 0.99
    momentum: 0.9
    start_epoch: 9
    end_epoch: 10000
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }

}
layers {
  name: "Layer2"
  input_dim: 2000
  num_units: 2000
  type: SIGMOID
  init_params {
    wt_sigma: 3.0
    biases_min: -5
    biases_max: -3
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.1
    epsilon_anneal_rate: 0.99
    momentum: 0.5
    start_epoch: 0
    end_epoch: 2
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.1
    epsilon_anneal_rate: 0.99
    momentum: 0.9
    start_epoch: 3
    end_epoch: 8
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.025
    epsilon_anneal_rate: 0.99
    momentum: 0.9
    start_epoch: 9
    end_epoch: 10000000
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }

}
layers {
  name: "OutputLayer"
  input_dim: 2000
  num_units: -1
  type: SOFTMAX
  init_params {
    wt_sigma: 3.0
    biases_min: -5
    biases_max: -3
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.1
    epsilon_anneal_rate: 0.99
    momentum: 0.5
    start_epoch: 0
    end_epoch: 2
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.1
    epsilon_anneal_rate: 0.99
    momentum: 0.9
    start_epoch: 3
    end_epoch: 8
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }
  learning_schedule {
    l1_wt: 0.0001
    l2_wt: 0.003
    epsilon: 0.025
    epsilon_anneal_rate: 0.99
    momentum: 0.9
    start_epoch: 9
    end_epoch: 1000000
    dropout_rate: 0.0
    wt_norm_constraint: 0.0
    ada_lambda: 0.0
  }

}
